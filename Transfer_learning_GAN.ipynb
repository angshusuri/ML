{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intern_main_project_complete.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZKZzWPZaP55j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2196
        },
        "outputId": "2fc6d07e-c290-465d-fcb6-5058ed34ae52",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258176091,
          "user_tz": -330,
          "elapsed": 25152,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install -U -q PyDrive\n",
        "!pip install keras\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.4\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.12)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Selecting previously unselected package fontconfig.\n",
            "(Reading database ... 18298 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fontconfig_2.11.94-0ubuntu2_amd64.deb ...\n",
            "Unpacking fontconfig (2.11.94-0ubuntu2) ...\n",
            "Selecting previously unselected package libjbig0:amd64.\n",
            "Preparing to unpack .../01-libjbig0_2.1-3.1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
            "Selecting previously unselected package libcdt5.\n",
            "Preparing to unpack .../02-libcdt5_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libcdt5 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libcgraph6.\n",
            "Preparing to unpack .../03-libcgraph6_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libcgraph6 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libtiff5:amd64.\n",
            "Preparing to unpack .../04-libtiff5_4.0.8-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Selecting previously unselected package libwebp6:amd64.\n",
            "Preparing to unpack .../05-libwebp6_0.6.0-3_amd64.deb ...\n",
            "Unpacking libwebp6:amd64 (0.6.0-3) ...\n",
            "Selecting previously unselected package libxpm4:amd64.\n",
            "Preparing to unpack .../06-libxpm4_1%3a3.5.12-1_amd64.deb ...\n",
            "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Selecting previously unselected package libgd3:amd64.\n",
            "Preparing to unpack .../07-libgd3_2.2.5-3_amd64.deb ...\n",
            "Unpacking libgd3:amd64 (2.2.5-3) ...\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\n",
            "Preparing to unpack .../08-libpixman-1-0_0.34.0-1_amd64.deb ...\n",
            "Unpacking libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Selecting previously unselected package libxcb-render0:amd64.\n",
            "Preparing to unpack .../09-libxcb-render0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\n",
            "Preparing to unpack .../10-libxcb-shm0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libcairo2:amd64.\n",
            "Preparing to unpack .../11-libcairo2_1.14.10-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Selecting previously unselected package libltdl7:amd64.\n",
            "Preparing to unpack .../12-libltdl7_2.4.6-2_amd64.deb ...\n",
            "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
            "Selecting previously unselected package libthai-data.\n",
            "Preparing to unpack .../13-libthai-data_0.1.26-3_all.deb ...\n",
            "Unpacking libthai-data (0.1.26-3) ...\n",
            "Selecting previously unselected package libdatrie1:amd64.\n",
            "Preparing to unpack .../14-libdatrie1_0.2.10-5_amd64.deb ...\n",
            "Unpacking libdatrie1:amd64 (0.2.10-5) ...\n",
            "Selecting previously unselected package libthai0:amd64.\n",
            "Preparing to unpack .../15-libthai0_0.1.26-3_amd64.deb ...\n",
            "Unpacking libthai0:amd64 (0.1.26-3) ...\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\n",
            "Preparing to unpack .../16-libpango-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libgraphite2-3:amd64.\n",
            "Preparing to unpack .../17-libgraphite2-3_1.3.10-2_amd64.deb ...\n",
            "Unpacking libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Selecting previously unselected package libharfbuzz0b:amd64.\n",
            "Preparing to unpack .../18-libharfbuzz0b_1.4.2-1_amd64.deb ...\n",
            "Unpacking libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
            "Preparing to unpack .../19-libpangoft2-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
            "Preparing to unpack .../20-libpangocairo-1.0-0_1.40.12-1_amd64.deb ...\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Selecting previously unselected package libpathplan4.\n",
            "Preparing to unpack .../21-libpathplan4_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libpathplan4 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libgvc6.\n",
            "Preparing to unpack .../22-libgvc6_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libgvc6 (2.38.0-16ubuntu2) ...\n",
            "Selecting previously unselected package libgvpr2.\n",
            "Preparing to unpack .../23-libgvpr2_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking libgvpr2 (2.38.0-16ubuntu2) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libxt6:amd64.\r\n",
            "Preparing to unpack .../24-libxt6_1%3a1.1.5-1_amd64.deb ...\r\n",
            "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
            "Selecting previously unselected package libxmu6:amd64.\n",
            "Preparing to unpack .../25-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
            "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Selecting previously unselected package libxaw7:amd64.\n",
            "Preparing to unpack .../26-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
            "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Selecting previously unselected package graphviz.\n",
            "Preparing to unpack .../27-graphviz_2.38.0-16ubuntu2_amd64.deb ...\n",
            "Unpacking graphviz (2.38.0-16ubuntu2) ...\n",
            "Setting up libpathplan4 (2.38.0-16ubuntu2) ...\n",
            "Setting up libxcb-render0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
            "Setting up libdatrie1:amd64 (0.2.10-5) ...\n",
            "Setting up libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\n",
            "Setting up libgraphite2-3:amd64 (1.3.10-2) ...\n",
            "Setting up libpixman-1-0:amd64 (0.34.0-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
            "Setting up libxcb-shm0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxpm4:amd64 (1:3.5.12-1) ...\n",
            "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
            "Setting up libthai-data (0.1.26-3) ...\n",
            "Setting up libcdt5 (2.38.0-16ubuntu2) ...\n",
            "Setting up fontconfig (2.11.94-0ubuntu2) ...\n",
            "Regenerating fonts cache... done.\n",
            "Setting up libcgraph6 (2.38.0-16ubuntu2) ...\n",
            "Setting up libwebp6:amd64 (0.6.0-3) ...\n",
            "Setting up libcairo2:amd64 (1.14.10-1ubuntu1) ...\n",
            "Setting up libgvpr2 (2.38.0-16ubuntu2) ...\n",
            "Setting up libgd3:amd64 (2.2.5-3) ...\n",
            "Setting up libharfbuzz0b:amd64 (1.4.2-1) ...\n",
            "Setting up libthai0:amd64 (0.1.26-3) ...\n",
            "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
            "Setting up libpango-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.40.12-1) ...\n",
            "Setting up libgvc6 (2.38.0-16ubuntu2) ...\n",
            "Setting up graphviz (2.38.0-16ubuntu2) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mT4Al8OFybT2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "17051f5d-e0a7-41d1-8b87-43f1f17f832e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258206022,
          "user_tz": -330,
          "elapsed": 7717,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone --recursive https://github.com/leftthomas/ImageDeblurring.git\n",
        "!ls -l "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ImageDeblurring'...\n",
            "remote: Counting objects: 855, done.\u001b[K\n",
            "remote: Total 855 (delta 0), reused 0 (delta 0), pack-reused 855\u001b[K\n",
            "Receiving objects: 100% (855/855), 17.12 MiB | 48.83 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 May 21 17:02 datalab\n",
            "drwxr-xr-x 4 root root 4096 Jun  6 04:10 ImageDeblurring\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A3FhdcuY4rIA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e0a3007c-2244-4e9f-fd8c-bd22ef441ee1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258211693,
          "user_tz": -330,
          "elapsed": 2285,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l /content"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\r\n",
            "drwxr-xr-x 1 root root 4096 May 21 17:02 datalab\r\n",
            "drwxr-xr-x 4 root root 4096 Jun  6 04:10 ImageDeblurring\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1a3E-eTl6u-G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "709cfe62-e319-464a-ab73-1175cc31f7dc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528258226814,
          "user_tz": -330,
          "elapsed": 2538,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8kXKcNKVZ1-x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "pic_num = 301\n",
        "\n",
        "\n",
        "        \n",
        "dir = os.chdir('/content/ImageDeblurring/data/test/')\n",
        "\n",
        "if not os.path.exists('/content/ImageDeblurring/data/testdata'):\n",
        "        os.makedirs('/content/ImageDeblurring/data/testdata')\n",
        "        \n",
        "for file in os.listdir(dir):\n",
        "    img = cv2.imread('/content/ImageDeblurring/data/test/'+file)\n",
        "    resized_image = cv2.resize(img, (100, 100))\n",
        "    cv2.imwrite(\"/content/ImageDeblurring/data/testdata/\"+ file,resized_image)\n",
        "    #pic_num = pic_num + 1\n",
        "    #cv.imshow('exampleshq', thumbnail)\n",
        "    #cv.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    os.chdir('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyQVWyhSTud9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!ls -l /content/ImageDeblurring/data/small/testdata\n",
        "#os.chdir('/content')\n",
        "#!pwd\n",
        "#!mkdir -p result/test\n",
        "!mkdir -p result/finally\n",
        "#!mkdir weight\n",
        "#!mkdir -p result/interim\n",
        "#!ls -l /content/weight/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLZtmPb3PKDy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob as gb\n",
        "import os\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# normalization x to [-1,1]\n",
        "def normalization(x):\n",
        "    return x / 127.5 - 1\n",
        "\n",
        "\n",
        "# according the image path to read the image and covert it\n",
        "# to the given size, then slice it, finally return the full and blur images\n",
        "def format_image(image_path, size):\n",
        "    image = Image.open(image_path)\n",
        "    # slice image into full and blur images\n",
        "    image_full = image.crop((0, 0, image.size[0] / 2, image.size[1]))\n",
        "    # Note the full image in left, the blur image in right\n",
        "    image_blur = image.crop((image.size[0] / 2, 0, image.size[0], image.size[1]))\n",
        "\n",
        "    # image_full.show()\n",
        "    # image_blur.show()\n",
        "\n",
        "    image_full = image_full.resize((size, size), Image.ANTIALIAS)\n",
        "    image_blur = image_blur.resize((size, size), Image.ANTIALIAS)\n",
        "\n",
        "    # return the numpy arrays\n",
        "    return np.array(image_full), np.array(image_blur)\n",
        "\n",
        "\n",
        "# convert images to hdf5 data\n",
        "def build_hdf5(jpeg_dir, size=100):\n",
        "    # put data in HDF5\n",
        "    hdf5_file = os.path.join('/content/ImageDeblurring/data', 'data.h5')\n",
        "    with h5py.File(hdf5_file, 'w') as f:\n",
        "\n",
        "        for data_type in tqdm(['traindata', 'testdata'], desc='create HDF5 dataset from images'):\n",
        "            data_path = jpeg_dir + '/%s/*.jpg' % data_type\n",
        "            images_path = gb.glob(data_path)\n",
        "            # print(images_path)\n",
        "            data_full = []\n",
        "            data_blur = []\n",
        "            for image_path in images_path:\n",
        "                image_full, image_blur = format_image(image_path, size)\n",
        "                data_full.append(image_full)\n",
        "                data_blur.append(image_blur)\n",
        "\n",
        "            # print(len(data_full))\n",
        "            # print(len(data_blur))\n",
        "            f.create_dataset('%s_data_full' % data_type, data=data_full)\n",
        "            f.create_dataset('%s_data_blur' % data_type, data=data_blur)\n",
        "\n",
        "\n",
        "# load data by data type\n",
        "def load_data(data_type):\n",
        "    with h5py.File('/content/ImageDeblurring/data/data.h5', 'r') as f:\n",
        "        data_full = f['%s_data_full' % data_type][:].astype(np.float32)\n",
        "        data_full = normalization(data_full)\n",
        "\n",
        "        data_blur = f['%s_data_blur' % data_type][:].astype(np.float32)\n",
        "        data_blur = normalization(data_blur)\n",
        "\n",
        "        return data_full, data_blur\n",
        "\n",
        "\n",
        "def generate_image(full, blur, generated, path, epoch=None, index=None):\n",
        "    full = full * 127.5 + 127.5\n",
        "    blur = blur * 127.5 + 127.5\n",
        "    generated = generated * 127.5 + 127.5\n",
        "    for i in range(generated.shape[0]):\n",
        "        image_full = full[i, :, :, :]\n",
        "        image_blur = blur[i, :, :, :]\n",
        "        image_generated = generated[i, :, :, :]\n",
        "        image = np.concatenate((image_full, image_blur, image_generated), axis=1)\n",
        "        if (epoch is not None) and (index is not None):\n",
        "            Image.fromarray(image.astype(np.uint8)).save(path + str(epoch + 1) + '_' + str(index + 1) + '.png')\n",
        "        else:\n",
        "            Image.fromarray(image.astype(np.uint8)).save(path + str(i) + '.png')\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        " #   format_image('/content/ImageDeblurring/data/small/testdata/301.jpg', size=100)\n",
        " #   build_hdf5('/content/ImageDeblurring/data/small')\n",
        " #   img_full, img_blur = load_data('traindata')\n",
        " #   print(img_full, '\\n', len(img_blur))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEDB9LjZPKD0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65c43dbb-62d7-43ff-80c1-f71d23565d49",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528264219254,
          "user_tz": -330,
          "elapsed": 3973,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "#import data_utils\n",
        "\n",
        "# Note the image_shape must be multiple of patch_shape\n",
        "image_shape = (100, 100, 3)\n",
        "K_1 = 145\n",
        "K_2 = 170\n",
        "\n",
        "\n",
        "def l1_loss(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_pred - y_true))\n",
        "\n",
        "\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    # let the loss model can't be trained\n",
        "    loss_model.trainable = False\n",
        "    # loss_model.summary()\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "\n",
        "\n",
        "def generator_loss(y_true, y_pred):\n",
        "    return K_1 * perceptual_loss(y_true, y_pred) + K_2 * l1_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def adversarial_loss(y_true, y_pred):\n",
        "    return -K.log(y_pred)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    a, b = format_image('/content/ImageDeblurring/data/small/testdata/301.jpg', size=100)\n",
        "    print(l1_loss(a.astype(np.float32), b.astype(np.float32)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YhVqCRN6PKEE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 4794
        },
        "outputId": "de89d5eb-5812-4e29-f303-5b40295feb24",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528264276485,
          "user_tz": -330,
          "elapsed": 28699,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.core import Dropout, Dense, Flatten, Lambda\n",
        "from keras.layers.merge import Average\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# the paper defined hyper-parameter:chr\n",
        "channel_rate = 25\n",
        "# Note the image_shape must be multiple of patch_shape\n",
        "image_shape = (100, 100, 3)\n",
        "patch_shape = (channel_rate, channel_rate, 3)\n",
        "\n",
        "\n",
        "# Dense Block\n",
        "def dense_block(inputs, dilation_factor=None):\n",
        "    x = LeakyReLU(alpha=0.2)(inputs)\n",
        "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # the 3 Ã— 3 convolutions along the dense field are alternated between â€˜spatialâ€™ convolution\n",
        "    # and â€˜dilatedâ€™ convolution with linearly increasing dilation factor\n",
        "    if dilation_factor is not None:\n",
        "        x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same',\n",
        "                          dilation_rate=dilation_factor)(x)\n",
        "    else:\n",
        "        x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    # add Gaussian noise\n",
        "    x = Dropout(rate=0.5)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def generator_model():\n",
        "    # Input Image, Note the shape is variable\n",
        "    inputs = Input(shape=(None, None, 3))\n",
        "    # The Head\n",
        "    h = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), padding='same')(inputs)\n",
        "\n",
        "    # The Dense Field\n",
        "    d_1 = dense_block(inputs=h)\n",
        "    x = concatenate([h, d_1])\n",
        "    # the paper used dilated convolution at every even numbered layer within the dense field\n",
        "    d_2 = dense_block(inputs=x, dilation_factor=(1, 1))\n",
        "    x = concatenate([x, d_2])\n",
        "    d_3 = dense_block(inputs=x)\n",
        "    x = concatenate([x, d_3])\n",
        "    d_4 = dense_block(inputs=x, dilation_factor=(2, 2))\n",
        "    x = concatenate([x, d_4])\n",
        "    d_5 = dense_block(inputs=x)\n",
        "    x = concatenate([x, d_5])\n",
        "    d_6 = dense_block(inputs=x, dilation_factor=(3, 3))\n",
        "    x = concatenate([x, d_6])\n",
        "    d_7 = dense_block(inputs=x)\n",
        "    x = concatenate([x, d_7])\n",
        "    d_8 = dense_block(inputs=x, dilation_factor=(2, 2))\n",
        "    x = concatenate([x, d_8])\n",
        "    d_9 = dense_block(inputs=x)\n",
        "    x = concatenate([x, d_9])\n",
        "    d_10 = dense_block(inputs=x, dilation_factor=(1, 1))\n",
        "    # The Tail\n",
        "    x = LeakyReLU(alpha=0.2)(d_10)\n",
        "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # The Global Skip Connection\n",
        "    x = concatenate([h, x])\n",
        "    x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same')(x)\n",
        "    # PReLU can't be used, because it is connected with the input shape\n",
        "    # x = PReLU()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output Image\n",
        "    outputs = Convolution2D(filters=3, kernel_size=(3, 3), padding='same', activation='tanh')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_model():\n",
        "    # PatchGAN\n",
        "    inputs = Input(shape=patch_shape)\n",
        "    x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Convolution2D(filters=2 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(units=1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='PatchGAN')\n",
        "    # model.summary()\n",
        "\n",
        "    # discriminator\n",
        "    inputs = Input(shape=image_shape)\n",
        "\n",
        "    list_row_idx = [(i * channel_rate, (i + 1) * channel_rate) for i in\n",
        "                    range(int(image_shape[0] / patch_shape[0]))]\n",
        "    list_col_idx = [(i * channel_rate, (i + 1) * channel_rate) for i in\n",
        "                    range(int(image_shape[1] / patch_shape[1]))]\n",
        "\n",
        "    list_patch = []\n",
        "    for row_idx in list_row_idx:\n",
        "        for col_idx in list_col_idx:\n",
        "            x_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(inputs)\n",
        "            list_patch.append(x_patch)\n",
        "\n",
        "    x = [model(patch) for patch in list_patch]\n",
        "    outputs = Average()(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Discriminator')\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator_containing_discriminator(generator, discriminator):\n",
        "    inputs = Input(shape=image_shape)\n",
        "    generated_image = generator(inputs)\n",
        "    outputs = discriminator(generated_image)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    g = generator_model()\n",
        "    g.summary()\n",
        "    d = discriminator_model()\n",
        "    d.summary()\n",
        "    plot_model(d)\n",
        "    m = generator_containing_discriminator(generator_model(), discriminator_model())\n",
        "    m.summary()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 1 2800        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 1 10100       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 1 400         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 2 22525       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 2 100         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, None, 2 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 1 0           conv2d_1[0][0]                   \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 1 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 1 12600       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 1 400         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 2 22525       leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 2 100         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, None, 2 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 1 0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 1 15100       leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 400         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 2 22525       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 2 100         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, None, 2 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, None, 1 0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 1 17600       leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 400         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 2 22525       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 2 100         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, None, None, 2 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, None, None, 2 0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 2 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 1 20100       leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 400         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 100         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, None, None, 2 0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 2 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 1 22600       leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 400         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 100         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, None, None, 2 0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 2 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 1 25100       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 400         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 100         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, None, None, 2 0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 2 0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 1 27600       leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 400         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 100         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, None, None, 3 0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 3 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 1 30100       leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 400         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 100         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, None, None, 3 0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 3 0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 1 32600       leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 400         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 2 22525       leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 100         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 2 0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 1 2600        leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 400         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, None, None, 2 0           conv2d_1[0][0]                   \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 2 45025       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 3 678         leaky_re_lu_22[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 495,253\n",
            "Trainable params: 492,553\n",
            "Non-trainable params: 2,700\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 25, 25, 3)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "PatchGAN (Model)                (None, 1)            148701      lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "                                                                 lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "                                                                 lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "                                                                 lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "                                                                 lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_1 (Average)             (None, 1)            0           PatchGAN[1][0]                   \n",
            "                                                                 PatchGAN[2][0]                   \n",
            "                                                                 PatchGAN[3][0]                   \n",
            "                                                                 PatchGAN[4][0]                   \n",
            "                                                                 PatchGAN[5][0]                   \n",
            "                                                                 PatchGAN[6][0]                   \n",
            "                                                                 PatchGAN[7][0]                   \n",
            "                                                                 PatchGAN[8][0]                   \n",
            "                                                                 PatchGAN[9][0]                   \n",
            "                                                                 PatchGAN[10][0]                  \n",
            "                                                                 PatchGAN[11][0]                  \n",
            "                                                                 PatchGAN[12][0]                  \n",
            "                                                                 PatchGAN[13][0]                  \n",
            "                                                                 PatchGAN[14][0]                  \n",
            "                                                                 PatchGAN[15][0]                  \n",
            "                                                                 PatchGAN[16][0]                  \n",
            "==================================================================================================\n",
            "Total params: 148,701\n",
            "Trainable params: 148,151\n",
            "Non-trainable params: 550\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "Generator (Model)            multiple                  495253    \n",
            "_________________________________________________________________\n",
            "Discriminator (Model)        (None, 1)                 148701    \n",
            "=================================================================\n",
            "Total params: 643,954\n",
            "Trainable params: 640,704\n",
            "Non-trainable params: 3,250\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Kr_m64LPKEE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3165
        },
        "outputId": "69348e58-4656-4a44-e434-c7fe95313944",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528269119682,
          "user_tz": -330,
          "elapsed": 4077990,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob as gb\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#import data_utils\n",
        "#from losses import adversarial_loss, generator_loss\n",
        "#from model import generator_model, discriminator_model, generator_containing_discriminator\n",
        "\n",
        "\n",
        "def train(batch_size, epoch_num):\n",
        "    # Note the x(blur) in the second, the y(full) in the first\n",
        "    y_train, x_train = load_data(data_type='traindata')\n",
        "\n",
        "    # GAN\n",
        "    g = generator_model()\n",
        "    d = discriminator_model()\n",
        "    d_on_g = generator_containing_discriminator(g, d)\n",
        "\n",
        "    # compile the models, use default optimizer parameters\n",
        "    # generator use adversarial loss\n",
        "    g.compile(optimizer='adam', loss=generator_loss)\n",
        "    # discriminator use binary cross entropy loss\n",
        "    d.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    # adversarial net use adversarial loss\n",
        "    d_on_g.compile(optimizer='adam', loss=adversarial_loss)\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "        print('epoch: ', epoch + 1, '/', epoch_num)\n",
        "        print('batches: ', int(x_train.shape[0] / batch_size))\n",
        "\n",
        "        for index in range(int(x_train.shape[0] / batch_size)):\n",
        "            # select a batch data\n",
        "            image_blur_batch = x_train[index * batch_size:(index + 1) * batch_size]\n",
        "            image_full_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
        "            generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
        "\n",
        "            # output generated images for each 30 iters\n",
        "            if (index % 3 == 0) and (index != 0):\n",
        "                  generate_image(image_full_batch, image_blur_batch, generated_images,\n",
        "                                          'result/interim/', epoch, index)\n",
        "\n",
        "            # concatenate the full and generated images,\n",
        "            # the full images at top, the generated images at bottom\n",
        "            x = np.concatenate((image_full_batch, generated_images))\n",
        "\n",
        "            # generate labels for the full and generated images\n",
        "            y = [1] * batch_size + [0] * batch_size\n",
        "\n",
        "            # train discriminator\n",
        "            d_loss = d.train_on_batch(x, y)\n",
        "            print('batch %d d_loss : %f' % (index + 1, d_loss))\n",
        "\n",
        "            # let discriminator can't be trained\n",
        "            d.trainable = False      #change here\n",
        "\n",
        "            # train adversarial net\n",
        "            d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [1] * batch_size)\n",
        "            print('batch %d d_on_g_loss : %f' % (index + 1, d_on_g_loss))\n",
        "\n",
        "            # train generator\n",
        "            g_loss = g.train_on_batch(image_blur_batch, image_full_batch)\n",
        "            print('batch %d g_loss : %f' % (index + 1, g_loss))\n",
        "\n",
        "            # let discriminator can be trained\n",
        "            d.trainable = True\n",
        "\n",
        "            # output weights for generator and discriminator each 30 iters\n",
        "            if (index % 3 == 0) and (index != 0):\n",
        "                g.save_weights('weight/generator_weights.h5', True)\n",
        "                d.save_weights('weight/discriminator_weights.h5', True)\n",
        "\n",
        "\n",
        "def test(batch_size):\n",
        "    # Note the x(blur) in the second, the y(full) in the first\n",
        "    y_test, x_test = load_data(data_type='testdata')\n",
        "    g = generator_model()\n",
        "    g.load_weights('weight/generator_weights.h5')\n",
        "    generated_images = g.predict(x=x_test, batch_size=batch_size)\n",
        "    generate_image(y_test, x_test, generated_images, 'result/finally/')\n",
        "\n",
        "\n",
        "def test_pictures(batch_size):\n",
        "    data_path = '/content/ImageDeblurring/data/testdata/*.jpeg'\n",
        "    images_path = gb.glob(data_path)\n",
        "    data_blur = []\n",
        "    for image_path in images_path:\n",
        "        image_blur = Image.open(image_path)\n",
        "        data_blur.append(np.array(image_blur))\n",
        "\n",
        "    data_blur = np.array(data_blur).astype(np.float32)\n",
        "    data_blur = normalization(data_blur)\n",
        "\n",
        "    g = generator_model()\n",
        "    g.load_weights('weight/generator_weights.h5')\n",
        "    generated_images = g.predict(x=data_blur, batch_size=batch_size)\n",
        "    generated = generated_images * 127.5 + 127.5\n",
        "    for i in range(generated.shape[0]):\n",
        "        image_generated = generated[i, :, :, :]\n",
        "        Image.fromarray(image_generated.astype(np.uint8)).save('result/test/' + str(i) + '.png')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(batch_size=10, epoch_num=1)\n",
        "    test(10)\n",
        "    test_pictures(2)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1 / 1\n",
            "batches:  60\n",
            "batch 1 d_loss : 0.629318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 1 d_on_g_loss : 0.520445\n",
            "batch 1 g_loss : 15909.912109\n",
            "batch 2 d_loss : 0.519690\n",
            "batch 2 d_on_g_loss : 0.299375\n",
            "batch 2 g_loss : 12021.034180\n",
            "batch 3 d_loss : 0.763788\n",
            "batch 3 d_on_g_loss : 0.382001\n",
            "batch 3 g_loss : 12456.730469\n",
            "batch 4 d_loss : 0.658212\n",
            "batch 4 d_on_g_loss : 0.554184\n",
            "batch 4 g_loss : 11818.064453\n",
            "batch 5 d_loss : 0.448695\n",
            "batch 5 d_on_g_loss : 0.105389\n",
            "batch 5 g_loss : 11087.657227\n",
            "batch 6 d_loss : 0.334821\n",
            "batch 6 d_on_g_loss : 0.328490\n",
            "batch 6 g_loss : 10245.420898\n",
            "batch 7 d_loss : 0.318368\n",
            "batch 7 d_on_g_loss : 0.320592\n",
            "batch 7 g_loss : 9374.219727\n",
            "batch 8 d_loss : 0.234936\n",
            "batch 8 d_on_g_loss : 0.351288\n",
            "batch 8 g_loss : 8424.071289\n",
            "batch 9 d_loss : 0.095013\n",
            "batch 9 d_on_g_loss : 0.196853\n",
            "batch 9 g_loss : 8893.067383\n",
            "batch 10 d_loss : 0.116044\n",
            "batch 10 d_on_g_loss : 0.584265\n",
            "batch 10 g_loss : 9565.675781\n",
            "batch 11 d_loss : 0.176972\n",
            "batch 11 d_on_g_loss : 0.119045\n",
            "batch 11 g_loss : 7816.370117\n",
            "batch 12 d_loss : 0.052456\n",
            "batch 12 d_on_g_loss : 0.054786\n",
            "batch 12 g_loss : 7425.731445\n",
            "batch 13 d_loss : 0.182145\n",
            "batch 13 d_on_g_loss : 0.573001\n",
            "batch 13 g_loss : 7158.595215\n",
            "batch 14 d_loss : 0.124471\n",
            "batch 14 d_on_g_loss : 0.573049\n",
            "batch 14 g_loss : 7892.434570\n",
            "batch 15 d_loss : 0.258363\n",
            "batch 15 d_on_g_loss : 0.570076\n",
            "batch 15 g_loss : 8329.473633\n",
            "batch 16 d_loss : 0.171836\n",
            "batch 16 d_on_g_loss : 0.571292\n",
            "batch 16 g_loss : 6415.611816\n",
            "batch 17 d_loss : 0.344026\n",
            "batch 17 d_on_g_loss : 0.289201\n",
            "batch 17 g_loss : 7038.225586\n",
            "batch 18 d_loss : 0.491111\n",
            "batch 18 d_on_g_loss : 0.259294\n",
            "batch 18 g_loss : 7117.930664\n",
            "batch 19 d_loss : 0.436463\n",
            "batch 19 d_on_g_loss : 0.128223\n",
            "batch 19 g_loss : 7537.024414\n",
            "batch 20 d_loss : 0.305946\n",
            "batch 20 d_on_g_loss : 0.124371\n",
            "batch 20 g_loss : 7084.098633\n",
            "batch 21 d_loss : 0.276029\n",
            "batch 21 d_on_g_loss : 0.118213\n",
            "batch 21 g_loss : 7789.803711\n",
            "batch 22 d_loss : 0.159813\n",
            "batch 22 d_on_g_loss : 0.229894\n",
            "batch 22 g_loss : 6433.625000\n",
            "batch 23 d_loss : 0.110638\n",
            "batch 23 d_on_g_loss : 0.052281\n",
            "batch 23 g_loss : 7210.671875\n",
            "batch 24 d_loss : 0.070715\n",
            "batch 24 d_on_g_loss : 0.021435\n",
            "batch 24 g_loss : 6754.516602\n",
            "batch 25 d_loss : 0.103256\n",
            "batch 25 d_on_g_loss : 0.510902\n",
            "batch 25 g_loss : 5762.557617\n",
            "batch 26 d_loss : 0.052302\n",
            "batch 26 d_on_g_loss : 0.022046\n",
            "batch 26 g_loss : 6101.696777\n",
            "batch 27 d_loss : 0.154188\n",
            "batch 27 d_on_g_loss : 0.106585\n",
            "batch 27 g_loss : 6903.751465\n",
            "batch 28 d_loss : 0.037283\n",
            "batch 28 d_on_g_loss : 0.318528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 28 g_loss : 6184.250977\n",
            "batch 29 d_loss : 0.046018\n",
            "batch 29 d_on_g_loss : 0.258204\n",
            "batch 29 g_loss : 7006.880371\n",
            "batch 30 d_loss : 0.295024\n",
            "batch 30 d_on_g_loss : 0.007033\n",
            "batch 30 g_loss : 6615.312500\n",
            "batch 31 d_loss : 0.058829\n",
            "batch 31 d_on_g_loss : 0.026254\n",
            "batch 31 g_loss : 5779.581055\n",
            "batch 32 d_loss : 0.138609\n",
            "batch 32 d_on_g_loss : 0.007409\n",
            "batch 32 g_loss : 5232.753906\n",
            "batch 33 d_loss : 0.260315\n",
            "batch 33 d_on_g_loss : 0.016295\n",
            "batch 33 g_loss : 5354.835449\n",
            "batch 34 d_loss : 0.376455\n",
            "batch 34 d_on_g_loss : 0.028436\n",
            "batch 34 g_loss : 4363.938477\n",
            "batch 35 d_loss : 0.832246\n",
            "batch 35 d_on_g_loss : 0.016399\n",
            "batch 35 g_loss : 5568.643066\n",
            "batch 36 d_loss : 0.379841\n",
            "batch 36 d_on_g_loss : 0.273492\n",
            "batch 36 g_loss : 5525.744141\n",
            "batch 37 d_loss : 0.358671\n",
            "batch 37 d_on_g_loss : 0.229132\n",
            "batch 37 g_loss : 5380.229492\n",
            "batch 38 d_loss : 0.350960\n",
            "batch 38 d_on_g_loss : 0.060484\n",
            "batch 38 g_loss : 5670.647461\n",
            "batch 39 d_loss : 0.305528\n",
            "batch 39 d_on_g_loss : 0.145811\n",
            "batch 39 g_loss : 5627.393555\n",
            "batch 40 d_loss : 0.468667\n",
            "batch 40 d_on_g_loss : 0.254723\n",
            "batch 40 g_loss : 4122.094727\n",
            "batch 41 d_loss : 0.737991\n",
            "batch 41 d_on_g_loss : 0.013425\n",
            "batch 41 g_loss : 5797.196289\n",
            "batch 42 d_loss : 0.477616\n",
            "batch 42 d_on_g_loss : 0.013536\n",
            "batch 42 g_loss : 4646.455078\n",
            "batch 43 d_loss : 0.428185\n",
            "batch 43 d_on_g_loss : 0.011787\n",
            "batch 43 g_loss : 5108.513184\n",
            "batch 44 d_loss : 0.562239\n",
            "batch 44 d_on_g_loss : 0.284865\n",
            "batch 44 g_loss : 4967.570801\n",
            "batch 45 d_loss : 1.003579\n",
            "batch 45 d_on_g_loss : 0.604471\n",
            "batch 45 g_loss : 4083.513184\n",
            "batch 46 d_loss : 0.553998\n",
            "batch 46 d_on_g_loss : 0.522968\n",
            "batch 46 g_loss : 4493.238770\n",
            "batch 47 d_loss : 0.526809\n",
            "batch 47 d_on_g_loss : 0.667055\n",
            "batch 47 g_loss : 5911.695801\n",
            "batch 48 d_loss : 0.413253\n",
            "batch 48 d_on_g_loss : 0.014694\n",
            "batch 48 g_loss : 5699.283691\n",
            "batch 49 d_loss : 0.348329\n",
            "batch 49 d_on_g_loss : 0.048192\n",
            "batch 49 g_loss : 5060.266113\n",
            "batch 50 d_loss : 0.368270\n",
            "batch 50 d_on_g_loss : 0.315452\n",
            "batch 50 g_loss : 5297.912109\n",
            "batch 51 d_loss : 0.313190\n",
            "batch 51 d_on_g_loss : 0.041946\n",
            "batch 51 g_loss : 4342.776855\n",
            "batch 52 d_loss : 0.360965\n",
            "batch 52 d_on_g_loss : 0.351742\n",
            "batch 52 g_loss : 4312.209961\n",
            "batch 53 d_loss : 0.453076\n",
            "batch 53 d_on_g_loss : 0.086458\n",
            "batch 53 g_loss : 4117.095703\n",
            "batch 54 d_loss : 0.350993\n",
            "batch 54 d_on_g_loss : 0.028947\n",
            "batch 54 g_loss : 3861.951660\n",
            "batch 55 d_loss : 0.413145\n",
            "batch 55 d_on_g_loss : 0.222636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "batch 55 g_loss : 4751.438965\n",
            "batch 56 d_loss : 0.604372\n",
            "batch 56 d_on_g_loss : 0.069115\n",
            "batch 56 g_loss : 5000.798340\n",
            "batch 57 d_loss : 0.552567\n",
            "batch 57 d_on_g_loss : 0.129236\n",
            "batch 57 g_loss : 4426.183594\n",
            "batch 58 d_loss : 0.513010\n",
            "batch 58 d_on_g_loss : 0.171305\n",
            "batch 58 g_loss : 4287.713867\n",
            "batch 59 d_loss : 0.503296\n",
            "batch 59 d_on_g_loss : 0.076203\n",
            "batch 59 g_loss : 3381.321045\n",
            "batch 60 d_loss : 0.588450\n",
            "batch 60 d_on_g_loss : 0.405817\n",
            "batch 60 g_loss : 3093.392090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S4VrXKuEspAh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fb524098-824e-46f3-b9a2-f56ec21f8fca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528269736326,
          "user_tz": -330,
          "elapsed": 2164,
          "user": {
            "displayName": "Angshuman Chatterjee",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "118315880813400788589"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#dir = os.chdir('/content/result/finally')\n",
        "\n",
        "#!tar -cvzf testresult.tgz /content/result/test\n",
        "!ls -l /content/result/test\n",
        "#!ls -l   /content/ImageDeblurring/data/    \n",
        "#for file in os.listdir(dir):\n",
        "#files.download('testresult.tgz')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 32\r\n",
            "-rw-r--r-- 1 root root 13598 Jun  6 07:11 0.png\r\n",
            "-rw-r--r-- 1 root root 11415 Jun  6 07:11 1.png\r\n",
            "-rw-r--r-- 1 root root  2096 Jun  6 07:11 2.png\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}